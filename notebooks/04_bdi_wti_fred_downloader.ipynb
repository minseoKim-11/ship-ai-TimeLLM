{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e649ba-43a8-420e-8ed2-238476c29e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas pandas-datareader yfinance quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "423b0af2-b6a1-41f3-b1ea-81c080478ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added project root to sys.path: /workspace/ship-ai\n",
      "--- Creating macro_data.csv (Plan D) ---\n",
      "Period: 2015-01-01 to 2025-11-01\n",
      "1/3: Fetching WTI (CL=F) and BDI Proxy (BDRY) from yfinance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3242/930534460.py:33: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(['CL=F', 'BDRY'], start=START_DATE, end=END_DATE)\n",
      "[*********************100%***********************]  2 of 2 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Fetched WTI data: 2725 rows\n",
      "  > Fetched BDI Proxy (BDRY) data: 2725 rows\n",
      "2/3: Fetching Newbuild Proxy (PCU336611336611) from FRED...\n",
      "  > Fetched Proxy data: 128 rows\n",
      "  > 2015 Base Value for rebasing: 203.89\n",
      "3/3: Combining, resampling to daily, and forward-filling...\n",
      "\n",
      "--- Success! ---\n",
      "Saved macro_data.csv to: /workspace/ship-ai/data/processed/macro_data.csv\n",
      "\n",
      "--- Data Head (5 rows) ---\n",
      "                  wti  bdi_proxy  newbuild_proxy_2015_100\n",
      "2015-01-01        NaN        NaN                 99.07222\n",
      "2015-01-02  52.689999        NaN                 99.07222\n",
      "2015-01-03  52.689999        NaN                 99.07222\n",
      "2015-01-04  52.689999        NaN                 99.07222\n",
      "2015-01-05  50.040001        NaN                 99.07222\n",
      "\n",
      "--- Data Tail (5 rows) ---\n",
      "                  wti  bdi_proxy  newbuild_proxy_2015_100\n",
      "2025-10-28  60.150002      7.953               126.601545\n",
      "2025-10-29  60.480000      8.200               126.601545\n",
      "2025-10-30  60.570000      8.250               126.601545\n",
      "2025-10-31  60.980000      8.100               126.601545\n",
      "2025-11-01  60.980000      8.100               126.601545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- 0. 설정 ---\n",
    "\n",
    "# 프로젝트 루트 경로\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "    print(f\"Added project root to sys.path: {PROJECT_ROOT}\")\n",
    "\n",
    "# 데이터 기간 설정 (리베이스를 위해 2015년부터 시작)\n",
    "START_DATE = datetime.datetime(2015, 1, 1)\n",
    "END_DATE = datetime.datetime.now()\n",
    "\n",
    "# 저장 경로\n",
    "SAVE_DIR = os.path.join(PROJECT_ROOT, \"data\", \"processed\")\n",
    "SAVE_FILE_PATH = os.path.join(SAVE_DIR, \"macro_data.csv\")\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"--- Creating macro_data.csv (Plan D) ---\")\n",
    "print(f\"Period: {START_DATE.date()} to {END_DATE.date()}\")\n",
    "\n",
    "# --- 1. WTI 및 BDI 프록시 (BDRY) 동시 조회 (yfinance) ---\n",
    "# [!!!] 커널 재시작 후 이 셀만 단독으로 실행하세요 [!!!]\n",
    "print(\"1/3: Fetching WTI (CL=F) and BDI Proxy (BDRY) from yfinance...\")\n",
    "try:\n",
    "    # 두 티커를 리스트로 묶어 한 번에 요청\n",
    "    data = yf.download(['CL=F', 'BDRY'], start=START_DATE, end=END_DATE)\n",
    "    \n",
    "    # yfinance가 멀티-레벨 컬럼으로 반환하므로 'Close' 가격만 추출\n",
    "    wti_series = data['Close']['CL=F'].rename('wti')\n",
    "    bdi_series = data['Close']['BDRY'].rename('bdi_proxy')\n",
    "    \n",
    "    print(f\"  > Fetched WTI data: {len(wti_series)} rows\")\n",
    "    print(f\"  > Fetched BDI Proxy (BDRY) data: {len(bdi_series)} rows\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  > yfinance Fetch FAILED: {e}\")\n",
    "    # 실패 시에도 코드가 중단되지 않도록 빈 시리즈 생성\n",
    "    wti_series = pd.Series(dtype='float64', name='wti') \n",
    "    bdi_series = pd.Series(dtype='float64', name='bdi_proxy')\n",
    "\n",
    "# --- 2. 신조선가 프록시 (FRED PPI) 불러오기 및 리베이스 ---\n",
    "print(\"2/3: Fetching Newbuild Proxy (PCU336611336611) from FRED...\")\n",
    "try:\n",
    "    proxy_df = web.DataReader('PCU336611336611', 'fred', START_DATE, END_DATE)\n",
    "    proxy_series = proxy_df['PCU336611336611']\n",
    "    \n",
    "    # 2015년 평균값 계산 (리베이스 기준)\n",
    "    base_value = proxy_series['2015'].mean()\n",
    "    \n",
    "    # 2015=100으로 리베이스\n",
    "    rebased_series = (proxy_series / base_value) * 100\n",
    "    rebased_series.name = 'newbuild_proxy_2015_100'\n",
    "    \n",
    "    print(f\"  > Fetched Proxy data: {len(rebased_series)} rows\")\n",
    "    print(f\"  > 2015 Base Value for rebasing: {base_value:.2f}\")\n",
    "except Exception as e:\n",
    "    print(f\"  > Proxy Fetch FAILED: {e}\")\n",
    "    rebased_series = pd.Series(dtype='float64', name='newbuild_proxy_2015_100')\n",
    "\n",
    "# --- 3. 데이터 병합, 일별 리샘플링 및 ffill ---\n",
    "print(\"3/3: Combining, resampling to daily, and forward-filling...\")\n",
    "\n",
    "# 기준이 될 일별 캘린더 생성\n",
    "daily_calendar = pd.date_range(start=START_DATE, end=END_DATE, freq='D')\n",
    "master_df = pd.DataFrame(index=daily_calendar)\n",
    "\n",
    "# 3개 시리즈를 마스터 캘린더에 병합 (join)\n",
    "master_df = master_df.join(wti_series)\n",
    "master_df = master_df.join(bdi_series) \n",
    "master_df = master_df.join(rebased_series)\n",
    "\n",
    "# [핵심] ffill (Forward Fill) 적용\n",
    "master_df = master_df.ffill()\n",
    "\n",
    "# 데이터가 시작되기 전의 맨 앞쪽 NaN 값들 제거\n",
    "master_df = master_df.dropna(how='all') # 'any' -> 'all' (모든 컬럼이 NaN인 행만 제거)\n",
    "\n",
    "# --- 4. CSV 파일로 저장 ---\n",
    "master_df.to_csv(SAVE_FILE_PATH, index=True, index_label='date')\n",
    "\n",
    "print(\"\\n--- Success! ---\")\n",
    "print(f\"Saved macro_data.csv to: {SAVE_FILE_PATH}\")\n",
    "print(\"\\n--- Data Head (5 rows) ---\")\n",
    "print(master_df.head())\n",
    "print(\"\\n--- Data Tail (5 rows) ---\")\n",
    "print(master_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c1a987-a1b1-4f92-b4e4-44573f6ff04f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
