{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea21a155-a5ed-454e-ae60-14718c3f8efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /workspace/ship-ai/data/processed/final_master_table_v2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- 0. 경로 설정 ---\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, \"data\", \"processed\")\n",
    "FINAL_MASTER_FILE = os.path.join(DATA_DIR, \"final_master_table_v2.csv\")\n",
    "\n",
    "# --- 1. DataHandler 클래스 정의 ---\n",
    "\n",
    "class DataHandler:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.data_by_ticker = {}\n",
    "        self.tickers = []\n",
    "        self._load_and_process_data()\n",
    "        \n",
    "    def _load_and_process_data(self):\n",
    "        try:\n",
    "            # 1. 'ticker'를 'str'로 읽어옴\n",
    "            df = pd.read_csv(\n",
    "                self.file_path, \n",
    "                parse_dates=['date'],\n",
    "                dtype={'ticker': str} \n",
    "            )\n",
    "            \n",
    "            # [!!! 최종 수정 !!!]\n",
    "            # 2. '0'이 누락된 문자열을 6자리로 채웁니다 (zero-fill)\n",
    "            #    '10140' -> '010140'\n",
    "            #    '9540'  -> '009540'\n",
    "            df['ticker'] = df['ticker'].str.zfill(6)\n",
    "            \n",
    "            df = df.set_index('date')\n",
    "            \n",
    "            # 3. 이제 self.tickers에는 '010140', '009540' 등이 담깁니다.\n",
    "            self.tickers = df['ticker'].unique()\n",
    "            \n",
    "            for ticker in self.tickers:\n",
    "                ticker_df = df[df['ticker'] == ticker].copy()\n",
    "                channel_cols = [col for col in ticker_df.columns if col not in ['ticker']]\n",
    "                self.data_by_ticker[ticker] = ticker_df[channel_cols]\n",
    "            \n",
    "            print(f\"[DataHandler] Success: Loaded and processed data for {len(self.tickers)} tickers.\")\n",
    "            print(f\"[DataHandler] Available tickers: {self.tickers}\") # <- '0'이 살아났는지 확인!\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"[DataHandler] Error: File not found at {self.file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[DataHandler] Error loading data: {e}\")\n",
    "\n",
    "    def get_data_by_ticker(self, ticker):\n",
    "        if ticker not in self.data_by_ticker:\n",
    "            print(f\"[DataHandler] Error: No data found for ticker {ticker}\")\n",
    "            return None\n",
    "        return self.data_by_ticker[ticker]\n",
    "\n",
    "    def get_all_tickers(self):\n",
    "        return self.tickers\n",
    "\n",
    "# --- 2. DataHandler 클래스 인스턴스화 및 테스트 ---\n",
    "print(f\"Loading data from: {FINAL_MASTER_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6343d602-2fa6-4240-8fcc-3badd0d6bc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataHandler] Success: Loaded and processed data for 6 tickers.\n",
      "[DataHandler] Available tickers: ['010140' '010620' '329180' '042660' '443060' '009540']\n",
      "\n",
      "--- Test: Get '010140' (삼성중공업) Data ---\n",
      "            close_log    ret_1d  trading_volume_log       roe  \\\n",
      "date                                                            \n",
      "2019-05-15   8.922125  0.016545           14.907388 -1.539182   \n",
      "2019-05-16   8.900413 -0.021712           14.858667 -1.539182   \n",
      "2019-05-17   8.884749 -0.015664           15.513969 -1.539182   \n",
      "2019-05-20   8.871786 -0.012963           14.881691 -1.539182   \n",
      "2019-05-21   8.882253  0.010467           14.772045 -1.539182   \n",
      "\n",
      "            real_debt_ratio  new_order_event_impulse  new_order_count_stair  \\\n",
      "date                                                                          \n",
      "2019-05-15       119.929095                      0.0                    1.0   \n",
      "2019-05-16       119.929095                      0.0                    1.0   \n",
      "2019-05-17       119.929095                      0.0                    1.0   \n",
      "2019-05-20       119.929095                      0.0                    1.0   \n",
      "2019-05-21       119.929095                      0.0                    1.0   \n",
      "\n",
      "            bdi_proxy        wti  newbuild_proxy_2015_100  imo_event_impulse  \\\n",
      "date                                                                           \n",
      "2019-05-15     11.800  62.020000               102.848735                0.0   \n",
      "2019-05-16     11.835  62.869999               102.848735                0.0   \n",
      "2019-05-17     12.025  62.759998               102.848735                0.0   \n",
      "2019-05-20     11.835  63.099998               102.848735                1.0   \n",
      "2019-05-21     11.965  62.990002               102.848735                0.0   \n",
      "\n",
      "            imo_event_decay  \n",
      "date                         \n",
      "2019-05-15         0.277390  \n",
      "2019-05-16         0.263520  \n",
      "2019-05-17         0.250344  \n",
      "2019-05-20         1.000000  \n",
      "2019-05-21         0.950000  \n",
      "\n",
      "Shape of data: (1388, 12)\n",
      "Columns (12 channels): ['close_log', 'ret_1d', 'trading_volume_log', 'roe', 'real_debt_ratio', 'new_order_event_impulse', 'new_order_count_stair', 'bdi_proxy', 'wti', 'newbuild_proxy_2015_100', 'imo_event_impulse', 'imo_event_decay']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# [1] 커널 재시작 후, [2] 위 셀을 먼저 실행하고, [3] 이 셀을 실행\n",
    "data_handler = DataHandler(FINAL_MASTER_FILE)\n",
    "\n",
    "# 테스트: '삼성중공업' (010140) 데이터 가져오기\n",
    "# 이제 if '010140' in ['010140', '009540', ...] 비교가 True가 됩니다.\n",
    "if '010140' in data_handler.get_all_tickers():\n",
    "    print(\"\\n--- Test: Get '010140' (삼성중공업) Data ---\")\n",
    "    samsung_df = data_handler.get_data_by_ticker('010140')\n",
    "    if samsung_df is not None:\n",
    "        print(samsung_df.head())\n",
    "        print(f\"\\nShape of data: {samsung_df.shape}\")\n",
    "        print(f\"Columns (12 channels): {list(samsung_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6cd5c9-b0a1-4c9a-9e94-d25c26ec639d",
   "metadata": {},
   "source": [
    "## Phase2-B : 윈도우 생성기 구현\n",
    "LLM에 넣기 위해 슬라이딩 윈도우 방식의 3D 데이터로 재구성합니다.\n",
    "<br>(샘플 수, 120일, 12개 채널) 형태의 numpy 배열(텐서)을 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df30223f-bc15-4272-ae63-006e685dcc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test: Creating Sliding Windows for '010140' ---\n",
      "Original data shape (2D): (1388, 12)\n",
      "Input sequence length: 120 days\n",
      "Output sequence length: 10 days\n",
      "\n",
      "[SUCCESS] Sliding windows created!\n",
      "  > X (Input Tensors) shape (3D): (1259, 120, 12)\n",
      "  > y (Target Tensors) shape (3D): (1259, 10, 12)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. 윈도우 생성기 함수 정의 ---\n",
    "\n",
    "def create_sliding_windows(data, input_seq_len, output_seq_len):\n",
    "    \"\"\"\n",
    "    DataFrame(2D)을 받아 슬라이딩 윈도우(3D) numpy 배열로 변환합니다.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): 12개 채널이 포함된 2D 데이터프레임\n",
    "        input_seq_len (int): 모델이 입력을 위해 볼 과거 날짜 (예: 120일)\n",
    "        output_seq_len (int): 모델이 예측할 미래 날짜 (예: 10일)\n",
    "        \n",
    "    Returns:\n",
    "        (np.array, np.array): (X: 입력 윈도우, y: 타겟 윈도우) \n",
    "                               X shape: (N, 120, 12), y shape: (N, 10, 12)\n",
    "    \"\"\"\n",
    "    \n",
    "    # DataFrame을 numpy 배열로 변환\n",
    "    data_np = data.values\n",
    "    n_samples = len(data_np)\n",
    "    \n",
    "    X = [] # 입력 (과거 120일)\n",
    "    y = [] # 타겟 (미래 10일)\n",
    "    \n",
    "    total_len = input_seq_len + output_seq_len\n",
    "    \n",
    "    # 윈도우를 한 칸씩 이동(slide)하며 데이터 추출\n",
    "    for i in range(n_samples - total_len + 1):\n",
    "        input_window = data_np[i : i + input_seq_len]\n",
    "        output_window = data_np[i + input_seq_len : i + total_len]\n",
    "        \n",
    "        X.append(input_window)\n",
    "        y.append(output_window)\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# --- 2. 윈도우 생성기 테스트 ---\n",
    "\n",
    "# (이전 셀에서 'data_handler'가 이미 생성되었다고 가정)\n",
    "if 'data_handler' in locals():\n",
    "    print(\"--- Test: Creating Sliding Windows for '010140' ---\")\n",
    "    \n",
    "    # 1. 삼성중공업(010140) 데이터 가져오기\n",
    "    samsung_df = data_handler.get_data_by_ticker('010140')\n",
    "    \n",
    "    if samsung_df is not None:\n",
    "        # 2. 모델 하이퍼파라미터 정의\n",
    "        INPUT_SEQ_LEN = 120  # 입력 시퀀스 길이 (약 6개월)\n",
    "        OUTPUT_SEQ_LEN = 10  # 예측 시퀀스 길이 (2주)\n",
    "        \n",
    "        print(f\"Original data shape (2D): {samsung_df.shape}\")\n",
    "        print(f\"Input sequence length: {INPUT_SEQ_LEN} days\")\n",
    "        print(f\"Output sequence length: {OUTPUT_SEQ_LEN} days\")\n",
    "\n",
    "        # 3. 윈도우 생성 함수 호출\n",
    "        X_samsung, y_samsung = create_sliding_windows(\n",
    "            samsung_df, \n",
    "            INPUT_SEQ_LEN, \n",
    "            OUTPUT_SEQ_LEN\n",
    "        )\n",
    "        \n",
    "        print(\"\\n[SUCCESS] Sliding windows created!\")\n",
    "        print(f\"  > X (Input Tensors) shape (3D): {X_samsung.shape}\")\n",
    "        print(f\"  > y (Target Tensors) shape (3D): {y_samsung.shape}\")\n",
    "        \n",
    "        # 예: X_samsung.shape이 (약 1200, 120, 12) 처럼 나오면 성공\n",
    "        \n",
    "    else:\n",
    "        print(\"[Error] '010140' data is None.\")\n",
    "else:\n",
    "    print(\"[Error] 'data_handler' is not defined. Please run Phase 2-A cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b240ce5-2394-46d5-84b8-9b95150cd6cc",
   "metadata": {},
   "source": [
    "## Phase2-B : 윈도우 생성기 구현\n",
    "12개 채널의 Scale 일치를 위해 Standardization을 진행합니다.\n",
    "<br>모든 12개 채널의 Scale을평균 0, 표준편차 1인 표준 정규 분포로 통일시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf075694-e435-45c4-9d52-2cbd8c5866b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- 0. 경로 설정 ---\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, \"data\", \"processed\")\n",
    "FINAL_MASTER_FILE = os.path.join(DATA_DIR, \"final_master_table_v2.csv\")\n",
    "\n",
    "# --- 1. [업그레이드된] DataHandler 클래스 정의 ---\n",
    "\n",
    "class DataHandler:\n",
    "    \"\"\"\n",
    "    [V2] 표준화(Standardization) 기능이 추가된 DataHandler.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_path, train_end_date='2022-12-31'):\n",
    "        \"\"\"\n",
    "        [수정] train_end_date를 받아 Scaler를 학습시킵니다.\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "        self.train_end_date = pd.to_datetime(train_end_date)\n",
    "        self.data_by_ticker = {}   # 원본 데이터 보관\n",
    "        self.scalers_by_ticker = {} # Ticker별 Scaler 보관\n",
    "        self.tickers = []\n",
    "        \n",
    "        self._load_and_process_data()\n",
    "        self._fit_scalers() # Scaler 학습 단계 추가\n",
    "        \n",
    "    def _load_and_process_data(self):\n",
    "        \"\"\"\n",
    "        [수정] 'ticker'를 zfill(6)로 채워서 로드합니다.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                self.file_path, \n",
    "                parse_dates=['date'],\n",
    "                dtype={'ticker': str} \n",
    "            )\n",
    "            df['ticker'] = df['ticker'].str.zfill(6)\n",
    "            df = df.set_index('date')\n",
    "            \n",
    "            self.tickers = df['ticker'].unique()\n",
    "            \n",
    "            for ticker in self.tickers:\n",
    "                ticker_df = df[df['ticker'] == ticker].copy()\n",
    "                channel_cols = [col for col in ticker_df.columns if col not in ['ticker']]\n",
    "                # [수정] 원본 데이터를 data_by_ticker에 저장\n",
    "                self.data_by_ticker[ticker] = ticker_df[channel_cols]\n",
    "            \n",
    "            print(f\"[DataHandler V2] Success: Loaded and processed data for {len(self.tickers)} tickers.\")\n",
    "            print(f\"[DataHandler V2] Available tickers: {self.tickers}\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"[DataHandler V2] Error: File not found at {self.file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[DataHandler V2] Error loading data: {e}\")\n",
    "\n",
    "    def _fit_scalers(self):\n",
    "        \"\"\"\n",
    "        [!!! NEW !!!]\n",
    "        데이터 리크(Leakage) 방지를 위해 'train_end_date' 이전 데이터로만\n",
    "        StandardScaler를 학습(fit)시킵니다.\n",
    "        \"\"\"\n",
    "        print(f\"[DataHandler V2] Fitting scalers using data up to {self.train_end_date.date()}...\")\n",
    "        for ticker in self.tickers:\n",
    "            # 1. 훈련 데이터 분리 (예: ~ 2022-12-31)\n",
    "            train_data = self.data_by_ticker[ticker].loc[:self.train_end_date]\n",
    "            \n",
    "            if train_data.empty:\n",
    "                print(f\"  > Warning: No training data for {ticker} before {self.train_end_date.date()}. Skipping scaler.\")\n",
    "                continue\n",
    "                \n",
    "            # 2. 12개 채널에 대한 Scaler 생성 및 학습\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(train_data) # [중요] 'fit'은 훈련 데이터로만!\n",
    "            \n",
    "            # 3. Ticker별로 학습된 Scaler 저장\n",
    "            self.scalers_by_ticker[ticker] = scaler\n",
    "        print(\"[DataHandler V2] Scalers fitted.\")\n",
    "\n",
    "    def get_scaled_data_by_ticker(self, ticker):\n",
    "        \"\"\"\n",
    "        [!!! NEW !!!]\n",
    "        원본 데이터를 Ticker에 맞는 Scaler로 'transform'하여 반환합니다.\n",
    "        \"\"\"\n",
    "        if ticker not in self.data_by_ticker:\n",
    "            print(f\"[DataHandler V2] Error: No data found for ticker {ticker}\")\n",
    "            return None\n",
    "        if ticker not in self.scalers_by_ticker:\n",
    "            print(f\"[DataHandler V2] Error: No scaler found for ticker {ticker}\")\n",
    "            return None\n",
    "\n",
    "        # 1. 원본 데이터 전체를 가져옴\n",
    "        original_data = self.data_by_ticker[ticker]\n",
    "        \n",
    "        # 2. \"학습된\" Scaler로 \"전체\" 데이터를 변환(transform)\n",
    "        scaled_data_np = self.scalers_by_ticker[ticker].transform(original_data)\n",
    "        \n",
    "        # 3. 다시 DataFrame으로 변환 (인덱스와 컬럼명 복원)\n",
    "        scaled_df = pd.DataFrame(\n",
    "            scaled_data_np, \n",
    "            index=original_data.index, \n",
    "            columns=original_data.columns\n",
    "        )\n",
    "        return scaled_df\n",
    "\n",
    "    def get_all_tickers(self):\n",
    "        return self.tickers\n",
    "\n",
    "# --- 2. [업그레이드된] DataHandler 테스트 ---\n",
    "print(f\"Loading data from: {FINAL_MASTER_FILE}\")\n",
    "\n",
    "# [1] 커널 재시작 후, [2] 위 셀을 먼저 실행하고, [3] 이 셀을 실행\n",
    "# (훈련 데이터는 2022년 말까지로 설정)\n",
    "data_handler_v2 = DataHandler(FINAL_MASTER_FILE, train_end_date='2022-12-31')\n",
    "\n",
    "# 테스트: '삼성중공업' (010140)의 \"표준화된\" 데이터 가져오기\n",
    "if '010140' in data_handler_v2.get_all_tickers():\n",
    "    print(\"\\n--- Test: Get '010140' (삼성중공업) SCALED Data ---\")\n",
    "    \n",
    "    scaled_samsung_df = data_handler_v2.get_scaled_data_by_ticker('010140')\n",
    "    \n",
    "    if scaled_samsung_df is not None:\n",
    "        print(scaled_samsung_df.head())\n",
    "        print(f\"\\nShape of scaled data: {scaled_samsung_df.shape}\")\n",
    "        \n",
    "        # [검증] 표준화가 잘 되었는지 평균/표준편차 확인\n",
    "        print(\"\\n--- Verification (Scaled Data Stats) ---\")\n",
    "        print(\" (평균은 0에 가깝고, 표준편차는 1에 가까워야 함)\")\n",
    "        print(scaled_samsung_df.describe().loc[['mean', 'std']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
