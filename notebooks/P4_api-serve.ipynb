{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628a08fb-a5e1-4087-b392-811a61bf83d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ (ship-ai)\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "APP_DIR = os.path.join(BASE_DIR, \"app\")\n",
    "\n",
    "# 1. app í´ë” ìƒì„±\n",
    "os.makedirs(APP_DIR, exist_ok=True)\n",
    "print(f\"âœ… Created Folder: {APP_DIR}\")\n",
    "\n",
    "# 2. __init__.py (ë¹ˆ íŒŒì¼)\n",
    "with open(os.path.join(APP_DIR, \"__init__.py\"), \"w\") as f:\n",
    "    pass\n",
    "\n",
    "# 3. schemas.py (ë°ì´í„° êµ¬ì¡°)\n",
    "schemas_code = \"\"\"\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "\n",
    "class PredictionRequest(BaseModel):\n",
    "    ticker: str\n",
    "\n",
    "class PredictionResponse(BaseModel):\n",
    "    ticker: str\n",
    "    current_price: float\n",
    "    predicted_prices: List[float]\n",
    "    direction: str\n",
    "    analysis_comment: str\n",
    "    key_factor: str\n",
    "\"\"\"\n",
    "with open(os.path.join(APP_DIR, \"schemas.py\"), \"w\", encoding='utf-8') as f:\n",
    "    f.write(schemas_code.strip())\n",
    "print(\"âœ… Created: schemas.py\")\n",
    "\n",
    "# 4. inference.py (ì¶”ë¡  ë¡œì§ - ê´´ë¦¬ ë¶„ì„ í¬í•¨)\n",
    "# (ì£¼ì˜: TimeLLM ê²½ë¡œëŠ” ì‹¤ì œ í™˜ê²½ì— ë§ì¶° ìˆ˜ì •ë  ìˆ˜ ìˆìŒ)\n",
    "inference_code = \"\"\"\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n",
    "\n",
    "# ëª¨ë¸ import ì‹œë„\n",
    "try:\n",
    "    from external.time_llm.models.TimeLLM import Model as TimeLLM\n",
    "except ImportError:\n",
    "    # ê²½ë¡œê°€ ë‹¤ë¥¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ models í´ë”ì—ì„œë„ ì‹œë„\n",
    "    try:\n",
    "        from models.TimeLLM import Model as TimeLLM\n",
    "    except:\n",
    "        print(\"âš ï¸ TimeLLM Model Import Failed. Check paths.\")\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self):\n",
    "        self.task_name = 'long_term_forecast'\n",
    "        self.is_training = 0\n",
    "        self.model_id = 'Stock_Prediction'\n",
    "        self.model = 'TimeLLM'\n",
    "        self.seq_len = 120\n",
    "        self.label_len = 60\n",
    "        self.pred_len = 10\n",
    "        self.enc_in = 12\n",
    "        self.dec_in = 12\n",
    "        self.c_out = 12\n",
    "        self.llm_model = 'GPT2'\n",
    "        self.llm_dim = 768\n",
    "        self.llm_layers = 12\n",
    "        self.patch_len = 8   # Ultimate\n",
    "        self.stride = 4      # Ultimate\n",
    "        self.d_model = 768   # Monster\n",
    "        self.d_ff = 768      # Monster (Fixed)\n",
    "        self.n_heads = 12\n",
    "        self.dropout = 0.0\n",
    "        self.prompt_domain = 1\n",
    "        self.content = \"Predict...\"\n",
    "\n",
    "def analyze_key_factors(df_window):\n",
    "    # ì»¬ëŸ¼ëª… ë§¤í•‘ (ì‹¤ì œ CSVì— ë§ê²Œ ìˆ˜ì • í•„ìš”)\n",
    "    # ì˜ˆ: 'brent', 'usd', 'bdi', 'interest_rate' ì»¬ëŸ¼ì´ ìˆë‹¤ê³  ê°€ì •\n",
    "    # ë§Œì•½ ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥´ë‹¤ë©´ ì—¬ê¸°ì„œ ìˆ˜ì •í•˜ì„¸ìš”!\n",
    "    changes = {}\n",
    "    \n",
    "    # ì˜ˆì‹œ ë¡œì§ (ë³€ë™ì„± ê³„ì‚°)\n",
    "    target_cols = ['brent', 'usd', 'bdi'] # ì£¼ìš” ê±°ì‹œ ì§€í‘œ\n",
    "    \n",
    "    for col in target_cols:\n",
    "        if col in df_window.columns:\n",
    "            try:\n",
    "                now = df_window[col].iloc[-1]\n",
    "                prev = df_window[col].iloc[-5] # 5ì¼ ì „ ëŒ€ë¹„\n",
    "                change = (now - prev) / (prev + 1e-5)\n",
    "                changes[col] = change\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "    if not changes:\n",
    "        return \"ì‹œì¥ ì „ë°˜\", 0.0\n",
    "        \n",
    "    top_factor = max(changes, key=lambda k: abs(changes[k]))\n",
    "    return top_factor, changes[top_factor]\n",
    "\n",
    "class Predictor:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.configs = Configs()\n",
    "        self.model = None\n",
    "        self.data = None\n",
    "        \n",
    "    def load_model(self, model_path):\n",
    "        # TimeLLM í´ë˜ìŠ¤ ì¬ì •ì˜ê°€ í•„ìš”í•  ìˆ˜ ìˆìŒ (í™˜ê²½ì— ë”°ë¼)\n",
    "        # ì—¬ê¸°ì„  ìœ„ì—ì„œ importí•œ TimeLLM ì‚¬ìš©\n",
    "        self.model = TimeLLM(self.configs)\n",
    "        state_dict = torch.load(model_path, map_location=self.device)\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        self.model.to(self.device).float()\n",
    "        self.model.eval()\n",
    "        print(f\"âœ… Model Loaded from {model_path}\")\n",
    "\n",
    "    def load_data(self, csv_path):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        # ë‚ ì§œ ì •ë ¬\n",
    "        if 'date' in self.data.columns:\n",
    "            self.data = self.data.sort_values('date')\n",
    "        print(f\"âœ… Data Loaded: {len(self.data)} rows\")\n",
    "\n",
    "    def predict(self, ticker):\n",
    "        # ë°ì´í„° í•„í„°ë§\n",
    "        df_ticker = self.data[self.data['ticker'] == ticker].copy()\n",
    "        if len(df_ticker) < 120:\n",
    "            return {\"error\": \"Not enough data\"}\n",
    "            \n",
    "        recent_window = df_ticker.iloc[-120:]\n",
    "        \n",
    "        # ì „ì²˜ë¦¬ (Standard Scaling - ì•½ì‹)\n",
    "        # ì‹¤ì œë¡  í•™ìŠµì‹œ ì‚¬ìš©í•œ Scalerë¥¼ ë¡œë“œí•´ì•¼ ì •í™•í•¨. ì—¬ê¸°ì„  êµ¬ê°„ Scaling\n",
    "        cols = [c for c in recent_window.columns if c not in ['date', 'ticker', 'ticker_name']]\n",
    "        vals = recent_window[cols].values\n",
    "        mean = np.mean(vals, axis=0)\n",
    "        std = np.std(vals, axis=0) + 1e-5\n",
    "        scaled = (vals - mean) / std\n",
    "        \n",
    "        batch_x = torch.tensor(scaled).unsqueeze(0).float().to(self.device)\n",
    "        \n",
    "        # ì¶”ë¡ \n",
    "        with torch.no_grad():\n",
    "            B, Seq, C = batch_x.shape\n",
    "            Pred = 10\n",
    "            dummy_mark_enc = torch.zeros(B, Seq, 4).to(self.device)\n",
    "            dummy_dec_in = torch.zeros(B, Pred, C).to(self.device)\n",
    "            dummy_mark_dec = torch.zeros(B, Pred, 4).to(self.device)\n",
    "            \n",
    "            outputs = self.model(batch_x, dummy_mark_enc, dummy_dec_in, dummy_mark_dec)\n",
    "            if isinstance(outputs, tuple): outputs = outputs[0]\n",
    "            \n",
    "        # ì—­ë³€í™˜\n",
    "        pred_scaled = outputs[0, -Pred:, :].cpu().numpy()\n",
    "        \n",
    "        # 0ë²ˆ ì»¬ëŸ¼ì´ Closeë¼ê³  ê°€ì •\n",
    "        pred_close = (pred_scaled[:, 0] * std[0]) + mean[0]\n",
    "        \n",
    "        current_price = recent_window.iloc[-1]['close']\n",
    "        factor_name, factor_val = analyze_key_factors(recent_window)\n",
    "        \n",
    "        # ì½”ë©˜íŠ¸ ìƒì„±\n",
    "        last_pred = pred_close[-1]\n",
    "        ratio = (last_pred - current_price) / current_price\n",
    "        \n",
    "        if ratio > 0.03:\n",
    "            direction = \"ìƒìŠ¹\"\n",
    "            cmt = f\"Time-LLMì€ ìƒìŠ¹ì„¸(ì•½ +{ratio*100:.1f}%)ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\"\n",
    "        elif ratio < -0.03:\n",
    "            direction = \"í•˜ë½\"\n",
    "            cmt = f\"Time-LLMì€ í•˜ë½ì„¸(ì•½ -{abs(ratio)*100:.1f}%)ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\"\n",
    "        else:\n",
    "            direction = \"ë³´í•©\"\n",
    "            cmt = \"Time-LLMì€ ì£¼ê°€ íš¡ë³´ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\"\n",
    "            \n",
    "        if abs(factor_val) > 0.01:\n",
    "            cmt += f\" (ì£¼ìš”ì¸: {factor_name} ë³€ë™)\"\n",
    "            \n",
    "        return {\n",
    "            \"ticker\": ticker,\n",
    "            \"current_price\": float(current_price),\n",
    "            \"predicted_prices\": pred_close.tolist(),\n",
    "            \"direction\": direction,\n",
    "            \"analysis_comment\": cmt,\n",
    "            \"key_factor\": factor_name\n",
    "        }\n",
    "\n",
    "predictor = Predictor()\n",
    "\"\"\"\n",
    "with open(os.path.join(APP_DIR, \"inference.py\"), \"w\", encoding='utf-8') as f:\n",
    "    f.write(inference_code.strip())\n",
    "print(\"âœ… Created: inference.py\")\n",
    "\n",
    "# 5. main.py (ì„œë²„ ì§„ì…ì )\n",
    "main_code = \"\"\"\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from app.schemas import PredictionRequest, PredictionResponse\n",
    "from app.inference import predictor\n",
    "import os\n",
    "\n",
    "app = FastAPI(title=\"Ship-AI Time-LLM Engine\")\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "async def startup_event():\n",
    "    print(\"ğŸš€ Server Starting...\")\n",
    "    BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n",
    "    \n",
    "    # íŒŒì¼ ê²½ë¡œ (í™˜ê²½ì— ë§ê²Œ ìˆ˜ì • ê°€ëŠ¥)\n",
    "    MODEL_PATH = os.path.join(BASE_DIR, \"models\", \"ship_time_llm_final.pth\")\n",
    "    DATA_PATH = os.path.join(BASE_DIR, \"data\", \"processed\", \"final_master_table_v2.csv\")\n",
    "    \n",
    "    if os.path.exists(MODEL_PATH):\n",
    "        predictor.load_model(MODEL_PATH)\n",
    "        predictor.load_data(DATA_PATH)\n",
    "    else:\n",
    "        print(\"âš ï¸ Model file not found. Waiting for training...\")\n",
    "\n",
    "@app.post(\"/predict\", response_model=PredictionResponse)\n",
    "def predict(request: PredictionRequest):\n",
    "    try:\n",
    "        return predictor.predict(request.ticker)\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\"\"\"\n",
    "with open(os.path.join(APP_DIR, \"main.py\"), \"w\", encoding='utf-8') as f:\n",
    "    f.write(main_code.strip())\n",
    "print(\"âœ… Created: main.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
